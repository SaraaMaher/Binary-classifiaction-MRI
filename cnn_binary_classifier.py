# -*- coding: utf-8 -*-
"""CNN Binary classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/SaraaMaher/1d7dba9404d352b0db44e49635e316f4/cnn-binary-classifier.ipynb
"""

from google.colab import drive
drive.mount('/content/drive/')

!pip install tflearn

import cv2
import numpy as np
import glob
import tensorflow as tf
import matplotlib.pyplot as plt
import os
from tensorflow.keras import datasets, layers, models
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.estimator import regression
from google.colab.patches import cv2_imshow
from tensorflow.keras.layers import Dense, BatchNormalization
from skimage.io import imread_collection
from sklearn.metrics import confusion_matrix
import itertools
from tensorflow import keras

from tensorflow.keras import optimizers
optimizers.RMSprop
optimizers.Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau
from keras.callbacks import EarlyStopping

!unzip /content/drive/MyDrive/BinaryModelnoaug.zip

path = "/content/drive/MyDrive/BinaryModelFull"
IMG_SIZE=224

def load_images_from_folder(path,l,Data,label):
    for filename in os.listdir(path):
        img = cv2.imread(os.path.join(path,filename))
        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img,(IMG_SIZE,IMG_SIZE),interpolation=cv2.INTER_LINEAR)
        img = img.reshape(img.shape+(1,)) 
        #img = img.astype(np.uint8)
        cv2.waitKey(0)
        # Blur the image for better edge detection
        img_blur = cv2.GaussianBlur(img, (3,3), 0)

       # Canny Edge Detection
        edges = cv2.Canny(image=img_blur, threshold1=30, threshold2=150) # Canny Edge Detection
       # Display Canny Edge Detection Image
        #cv2_imshow( edges)
        cv2.waitKey(0)
        cv2.waitKey(0)

        pts = np.argwhere(edges>0)
        y1,x1 = pts.min(axis=0)
        y2,x2 = pts.max(axis=0)

        ## crop the region
        cropped = img[y1:y2, x1:x2]
        cv2.imwrite("cropped.png", cropped)

        tagged = cv2.rectangle(img.copy(), (x1,y1), (x2,y2), (0,255,0), 3, cv2.LINE_AA)
        #cv2_imshow( tagged)
        cv2.waitKey()
        cv2.destroyAllWindows()
        if tagged is not None:
            Data.append(tagged)
            l = l.astype(np.uint8)
            label.append(l)

def load_data(path2):
  fullpath=path+path2
  Data=[]
  label=[]
  load_images_from_folder(fullpath+"/yes",np.array([0]),Data,label)
  load_images_from_folder(fullpath+"/no",np.array([1]),Data,label)
  Data=np.array(Data)
  label=np.array(label)
  return Data,label

Train_Data,Train_Label=load_data("/Training")
Test_Data,Test_Label=load_data("/Testing")
Validation_Data,validation_Label=load_data("/Validation")

Test_Label = keras.utils.to_categorical(Test_Label, 2)
Train_Label = keras.utils.to_categorical(Train_Label, 2)

Val_Label = keras.utils.to_categorical(validation_Label, 2)

print(Train_Label.shape)

import keras.backend as K
K.clear_session()

model = models.Sequential()
model.add(layers.Conv2D(16,(3,3), activation='relu',   input_shape=(224,224,1)))
model.add(layers.MaxPooling2D(pool_size=(2,2) ))


model.add(layers.Conv2D(32, (3,3),activation ='relu'))
model.add(layers.Conv2D(32, (3,3),activation ='relu' ))

model.add(layers.MaxPooling2D(pool_size = (2, 2) ))

model.add(layers.Conv2D(64, (3,3),activation ='relu' ))
model.add(layers.Conv2D(64, (3,3),activation ='relu' ))
model.add(layers.Conv2D(64, (3,3),activation ='relu' ))

model.add(layers.MaxPooling2D(pool_size = (2, 2) ))

model.add(layers.Conv2D(128, (3,3),activation ='relu' ))
model.add(layers.Conv2D(128, (3,3),activation ='relu' ))


model.add(layers.MaxPooling2D(pool_size = (2, 2) ))


model.add(layers.Flatten())
model.add(layers.Dense(256))


model.add(tf.keras.layers.Dense(2, activation = "softmax"))  

opt = keras.optimizers.Adam(learning_rate=0.0001)


model.compile(optimizer=opt ,loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'] )


history = model.fit(Train_Data,Train_Label,epochs=50,validation_data=(Validation_Data, Val_Label))

plt.plot(history.history['acc'], label='accuracy')
plt.plot(history.history['val_acc'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

test_loss, test_acc = model.evaluate(Test_Data,Test_Label, verbose=2)
print(test_acc)

loss_train = history.history['loss']
loss_val = history.history['val_loss']
epochs = range(1,35)
plt.plot(loss_train, 'g', label='Training loss')
plt.plot(loss_val, 'b', label='validation loss')
plt.title('Training and Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()



y_predict=model.predict(Test_Data)
classes_x=np.argmax(y_predict,axis=1)
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import multilabel_confusion_matrix
from sklearn import metrics
matrix = metrics.confusion_matrix(Test_Label,classes_x )
print(matrix)
matrix=np.flip(matrix) 
acc = (matrix[0][0] + matrix[-1][-1]) / np.sum(matrix)
prec=(matrix[0][0]/(matrix[0][0]+matrix[1][0]))
recall=(matrix[0][0]/(matrix[0][0]+matrix[0][1]))
sp=(matrix[1][1]/(matrix[1][1]+matrix[1][0]))
print(acc)
print(prec)
print(recall)
print(sp)